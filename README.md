# A Study on Deep Latent Representations of Stroke Lesion Imaging 

This repository contains the Python code, deep autoencoder models, model weights, and statistical results for a research project evaluating the reconstruction fidelity and prognostic clinical value of latent representations of stroke images generated by deep convolutional autoencoders.

> ⚠️ **Note**: This repository does **not** include raw clinical data due to privacy/ethics restrictions.
---

## Repository Contents

| Folder/File                           | Description                                                     |
|---------------------------------------|-----------------------------------------------------------------|
| `data_collection/`                    | Part I: collection, documentation and exploration of study data |
| `dimensionality reduction/`           | Part II: Autoencoders and linear latent transformations         |
| └──`autoencoder_utils/models`         | Autoencoder models                                              |
| └──`autoencoder_utils/outputs`        | Autoencoder weights, config logs, and trainings metrics         |
| └──`autoencoder_utils/`               | Autoencoder configs and utils                                   |
| └──`clinical_validation_nihss/`       | Prognostic evaluation for stroke severity measures              |
| └──`clinical_validation_cognition/`   | Prognostic evaluation for cognitive stroke outcome measures     |
| `statistical_analysis/`               | Part III: Main statistical analyses & visualisation                  |
| `requirements.txt`                    | Python dependencies (from `venv`)                               |
| `LICENSE`                             | MIT License                                                     |

---

## Reproducing the Analysis

This project was developed and run using Python 3.12.9 in a local `venv` environment.

### 1. Clone the repository
```bash
git clone https://github.com/ChrisSperber/lesion-image-autoencoder
cd lesion-image-autoencoder
```
### 2. Set up environment
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```
### 3. Install dependencies
```bash
pip install -r requirements.txt
```
### 4. Run Analysis

The main analysis scripts are sequentially ordered with alphabetic prefixes. See docstrings for further information.

---
## Autoencoder models and weights
The autoencoder models and weights can be applied to other data, requiring
- the defined model architecture in autoencoder_utils/models
- the stored model weights in autoencoder_utils/outputs
- the dataset class (aka data loader) autoencoder_utils/outputs/autoencoder_dataset.py
- several utility functions from dimensionality_reduction/utils.py

Note: A control condition included simple, linear autoencoders. These were dropped from the final manuscript and the weights were not uploaded to the repo, also due to their size being above the standard limit of Github.

---

### Details on input data
All input data are stroke lesion segmentations normalised into a common space, as documented in data_collection/a_verify_and_collect_lesion_data.csv.
The current models were trained on images with a size of 79 x 95 x 79 voxels, which were preprocessed and padded by the Dataset class defined in dimensionality_reduction/autoencoder_utils/autoencoder_dataset.py

---
### Hardware
The code was written and executed in Python (PyTorch v2.1.0, torchvision v0.22.0) on a desktop workstation with an NVIDIA GeForce GTX 1650 GPU (4 GB VRAM), an AMD Ryzen 5 3600 6-core CPU, and 16 GB RAM. GPU acceleration was implemented with CUDA 11.8.

---
### Reusability
Feel free to reuse and adapt the analysis code for similar datasets. The current code assumes all images to be located in the same reference space (like MNI space) and unified in shape and resolution.

---
### References
TBA

---
### Contact
For questions, contact Christoph Sperber (see corresponding author [here](https://link.springer.com/article/10.1007/s00429-022-02559-x)).

---
### License
This project is licensed under the MIT License — see [Project License](LICENSE) for details.